"""
Author: Joon Sung Park (joonspk@stanford.edu)
Modified: Ahmad Alkadri (ahmad.alkadri@outlook.com)

Description: Wrapper functions for calling LLM.
"""

import json
import re
import time
from langchain.llms import Ollama
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler


# *** Ollama (Llama2-13b) ***
# To be able to run this, we need to make sure the Ollama is already up and running in the background.
# Simply run the Ollama using 'ollama serve' and usually it'll be enough (make sure you've downloaded)
# the model chosen below though
llm = Ollama(
    base_url="http://localhost:11434",
    model="llama2",
    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),
)


def temp_sleep(seconds=0.1):
    """
    The function `temp_sleep` is used to pause the execution of the program for a specified number of
    seconds.

    @param seconds The `seconds` parameter is a float value that represents the number of seconds to
    sleep for. By default, it is set to 0.1 seconds.
    """
    time.sleep(seconds)


def LLM_request(prompt):
    """
    The function `LLM_request` takes a prompt as input, calls the `llm` class with the prompt, and
    returns the response.

    @param prompt The prompt is the input text or question that you want to pass to the LLM (Language
    Model) for generating a response.

    @return The function `LLM_request` returns the response generated by the `llm` class.
    """
    # temp_sleep()
    try:
        response = llm(prompt)
    except ValueError:
        print("Requested tokens exceed context window")
        # TODO: Add map-reduce or splitter to handle this error.
        return "LLM ERROR"
    return response


def catch_output(
    raw_prompt="""
Sure, here is the conversation between Maria Lopez and Klaus Mueller:

{
"output": [
["Maria Lopez", "Hi Klaus! How are you?"],
["Klaus Mueller", "I'm doing well, thanks. How about you?"],
["Maria Lopez", "I'm good. Just working on my physics degree and streaming games on Twitch to make some extra money."],
["Klaus Mueller", "That's interesting. I'm actually writing a research paper on the effects of gentrification in low-income communities."],
["Maria Lopez", "Oh, really? That sounds like a really important topic. Do you want to talk more about it?"],
["Klaus Mueller", "Yeah, I'd love to. It's been a fascinating project so far. Have you heard of the term gentrification?"],
["Maria Lopez", "Yes, I have. It's when wealthier people move into a neighborhood and change it in ways that push out the original residents."],
["Klaus Mueller", "Exactly. And it can have serious consequences for the community, like displacement and loss of cultural identity."],
["Maria Lopez", "That's so true. I've seen it happen in my neighborhood too. It's really sad."],
["Klaus Mueller", "Yeah, it is. But there are ways to fight back against gentrification, like community organizing and advocacy."],
["Maria Lopez", "I see. Well, I should probably get back to studying. It was nice chatting with you."],
["Klaus Mueller", "Yeah, same here. Maybe we can catch up again soon."]
]
}
""",
):
    """
    The function `catch_output` extracts a stringified dictionary from a given input string using
    regular expressions.

    @param raw_prompt The `raw_prompt` parameter is the input string that you want to search for a
    stringified dictionary.
    """
    # Regular expression to match a stringified dictionary
    pattern = r"(\{.*\})"

    # Use re.search to find the first occurrence of the pattern in the input string
    match = re.search(pattern, raw_prompt, re.DOTALL)

    # If a match was found, extract the stringified dictionary
    if match:
        stringified_dict = match.group(1)
        return stringified_dict
    else:
        raise ValueError("No stringified JSON/dictionary found.")


if __name__ == "__main__":
	prompt = """
---
Character 1: Maria Lopez is working on her physics degree and streaming games on Twitch to make some extra money. She visits Hobbs Cafe for studying and eating just about everyday.
Character 2: Klaus Mueller is writing a research paper on the effects of gentrification in low-income communities.

Past Context: 
138 minutes ago, Maria Lopez and Klaus Mueller were already conversing about conversing about Maria's research paper mentioned by Klaus This context takes place after that conversation.

Current Context: Maria Lopez was attending her Physics class (preparing for the next lecture) when Maria Lopez saw Klaus Mueller in the middle of working on his research paper at the library (writing the introduction).
Maria Lopez is thinking of initating a conversation with Klaus Mueller.
Current Location: library in Oak Hill College

(This is what is in Maria Lopez's head: Maria Lopez should remember to follow up with Klaus Mueller about his thoughts on her research paper. Beyond this, Maria Lopez doesn't necessarily know anything more about Klaus Mueller) 

(This is what is in Klaus Mueller's head: Klaus Mueller should remember to ask Maria Lopez about her research paper, as she found it interesting that he mentioned it. Beyond this, Klaus Mueller doesn't necessarily know anything more about Maria Lopez) 

Here is their conversation. 

Maria Lopez: "
---
Output the response to the prompt above in json. The output should be a list of list where the inner lists are in the form of ["<Name>", "<Utterance>"]. Output multiple utterances in ther conversation until the conversation comes to a natural conclusion.
Example output json:
{"output": "[["Jane Doe", "Hi!"], ["John Doe", "Hello there!"] ... ]"}
	"""

	result_prompt = LLM_request(prompt)
	clean_result_prompt = catch_output(result_prompt)

	# Save the output in a text file
	with open("result.txt", "w") as f:
		f.write(result_prompt)
    
	try:
		# Save the dictionary into a JSON file
		with open("result_clean.json", "w") as json_file:
			json_file.write(clean_result_prompt)
	except Exception as exce:
		print("Cannot save the prompt:", exce)
    
	print(catch_output(result_prompt))